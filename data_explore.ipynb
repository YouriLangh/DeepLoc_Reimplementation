{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DeepLoc EDA\n",
    "In this file we explore the different datasets published by DeepLoc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library imports\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import blosum as bl\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DeepLoc 1.0 Dataset\n",
    "We first explore the dataset published under the [HTU website](https://services.healthtech.dtu.dk/services/DeepLoc-1.0/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DeepLoc 1.0 EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data file for the original DeepLoc 1.0 dataset\n",
    "fasta_file_path = './data/deeploc_data_original.fasta'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define locations and their desired mapping for printing.\n",
    "location_categories = {\n",
    "    \"Nucleus\": [\"Nucleus\"],\n",
    "    \"Cytoplasm\": [\"Cytoplasm\"],\n",
    "    \"Extracellular\": [\"Extracellular\"],\n",
    "    \"Mitochondrion\": [\"Mitochondrion\"],\n",
    "    \"Cell membrane\": [\"Cell.membrane\"],\n",
    "    \"Endoplasmic reticulum (ER)\": [\"Endoplasmic.reticulum\"],\n",
    "    \"Plastid\": [\"Plastid\"],\n",
    "    \"Golgi apparatus\": [\"Golgi.apparatus\"],\n",
    "    \"Lysosome/Vacuole\": [\"Lysosome/Vacuole\"],\n",
    "    \"Peroxisome\": [\"Peroxisome\"]\n",
    "}\n",
    "\n",
    "# Find the locations for the sequence\n",
    "def normalize_location(header_line):\n",
    "    header_line = header_line.lower()\n",
    "    matches = set()\n",
    "    for category, keywords in location_categories.items():\n",
    "        for keyword in keywords:\n",
    "            if keyword.lower() in header_line: # Normalize, just in case.\n",
    "                matches.add(category)\n",
    "    return matches\n",
    "\n",
    "# Count the number of sequences for each location\n",
    "def count_locations(fasta_file_path):\n",
    "    location_counts = defaultdict(int)\n",
    "    with open(fasta_file_path, 'r') as fasta_file:\n",
    "        for line in fasta_file:\n",
    "            if line.startswith('>'):\n",
    "                matched_categories = normalize_location(line)\n",
    "                for category in matched_categories:\n",
    "                    location_counts[category] += 1\n",
    "    return location_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: This still allows the one sequence to have multiple locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Location counts:\n",
      "Nucleus: 4189\n",
      "Cytoplasm: 2688\n",
      "Extracellular: 1973\n",
      "Mitochondrion: 1510\n",
      "Cell membrane: 1340\n",
      "Endoplasmic reticulum (ER): 862\n",
      "Plastid: 757\n",
      "Golgi apparatus: 356\n",
      "Lysosome/Vacuole: 321\n",
      "Peroxisome: 154\n"
     ]
    }
   ],
   "source": [
    "location_counts = count_locations(fasta_file_path)\n",
    "\n",
    "# Print the counts for each location\n",
    "print(\"Location counts:\")\n",
    "for location in location_categories:\n",
    "    print(f\"{location}: {location_counts[location]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of sequences that only have one location\n",
    "def count_single_location_only(fasta_file_path):\n",
    "    location_counts = defaultdict(int)\n",
    "    with open(fasta_file_path, 'r') as fasta_file:\n",
    "        for line in fasta_file:\n",
    "            if line.startswith('>'):\n",
    "                matched_categories = normalize_location(line)\n",
    "                if len(matched_categories) == 1:\n",
    "                    category = next(iter(matched_categories))\n",
    "                    location_counts[category] += 1\n",
    "    return location_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Only Nucleus and Cytoplasm occurred together as locations for sequences "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Location counts:\n",
      "Nucleus: 4043\n",
      "Cytoplasm: 2542\n",
      "Extracellular: 1973\n",
      "Mitochondrion: 1510\n",
      "Cell membrane: 1340\n",
      "Endoplasmic reticulum (ER): 862\n",
      "Plastid: 757\n",
      "Golgi apparatus: 356\n",
      "Lysosome/Vacuole: 321\n",
      "Peroxisome: 154\n"
     ]
    }
   ],
   "source": [
    "location_counts = count_single_location_only(fasta_file_path)\n",
    "\n",
    "# Print the counts for each location\n",
    "print(\"Location counts:\")\n",
    "for location in location_categories:\n",
    "    print(f\"{location}: {location_counts[location]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We decided against using this dataset as the DeepLoc 2.0 offers a dataset with partitions where sequences are correctly homology reduced to 30% identity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DeepLoc 2.0/2.1 EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = './data/deeploc_data_2.1.csv'\n",
    "train_path = './data/deeploc2.1_training_processed.csv'\n",
    "test_path = './data/deeploc2.1_test_processed.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Location counts:\n",
      "Cytoplasm: 9870\n",
      "Nucleus: 9720\n",
      "Extracellular: 3301\n",
      "Cell membrane: 4187\n",
      "Mitochondrion: 2590\n",
      "Plastid: 1047\n",
      "Endoplasmic reticulum: 2180\n",
      "Lysosome/Vacuole: 1496\n",
      "Golgi apparatus: 1279\n",
      "Peroxisome: 304\n",
      "Total Number of sequences in dataset: 35974\n"
     ]
    }
   ],
   "source": [
    "# Count the number of sequences for each location in the CSV file\n",
    "df = pd.read_csv(csv_path, delimiter=',')\n",
    "\n",
    "# Columns corresponding to subcellular locations/columns in the CSV file\n",
    "location_columns = [\n",
    "        \"Cytoplasm\",\n",
    "        \"Nucleus\",\n",
    "        \"Extracellular\",\n",
    "        \"Cell membrane\",\n",
    "        \"Mitochondrion\",\n",
    "        \"Plastid\",\n",
    "        \"Endoplasmic reticulum\",\n",
    "        \"Lysosome/Vacuole\",\n",
    "        \"Golgi apparatus\",\n",
    "        \"Peroxisome\"\n",
    "        ]\n",
    "\n",
    "def count_locations(df):\n",
    "\n",
    "    # Count occurrences\n",
    "    location_counts = df[location_columns].sum().astype(int)\n",
    "\n",
    "    print(\"Location counts:\")\n",
    "    for location, count in location_counts.items():\n",
    "        print(f\"{location}: {count}\")\n",
    "    total = location_counts.sum()\n",
    "    print(f\"Total Number of sequences in dataset: {total}\")\n",
    "\n",
    "\n",
    "count_locations(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Location counts (single-label only):\n",
      "Cytoplasm: 4582\n",
      "Nucleus: 5462\n",
      "Extracellular: 2944\n",
      "Cell membrane: 2770\n",
      "Mitochondrion: 2062\n",
      "Plastid: 932\n",
      "Endoplasmic reticulum: 1331\n",
      "Lysosome/Vacuole: 761\n",
      "Golgi apparatus: 556\n",
      "Peroxisome: 219\n",
      "Total: 21619\n"
     ]
    }
   ],
   "source": [
    "# Filter out sequences with multiple locations\n",
    "def count_locations_single_label(df):\n",
    "\n",
    "    # Filter: keep only rows with exactly 1 location\n",
    "    df_single_label = df[df[location_columns].sum(axis=1) == 1]\n",
    "\n",
    "    # Count occurrences in single-label data\n",
    "    location_counts = df_single_label[location_columns].sum().astype(int)\n",
    "\n",
    "    print(\"Location counts (single-label only):\")\n",
    "    for location, count in location_counts.items():\n",
    "        print(f\"{location}: {count}\")\n",
    "    print(f\"Total: {location_counts.sum()}\")\n",
    "\n",
    "    return df_single_label\n",
    "\n",
    "# Returns a filtered DataFrame with sequences that have only one location\n",
    "df_filtered = count_locations_single_label(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Membrane type counts:\n",
      "0.0: 15261\n",
      "1.0: 6358\n"
     ]
    }
   ],
   "source": [
    "counts = df_filtered['Membrane'].value_counts()\n",
    "# Print the counts for each Membrane type\n",
    "print(\"Membrane type counts:\")\n",
    "for location, count in counts.items():\n",
    "    print(f\"{location}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: This dataset is used for k-fold testing. Meaning that over K iterations, K-1 are used for training and 1 is used for validation. Homology across folds was >30%\n",
    "\n",
    "Mentioned in $2.3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 16)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In DeepLoc 1.0, they also filtered out sequences with length < 40\n",
    "# Count the number of sequences with length < 40\n",
    "df_filtered[df_filtered['Sequence'].str.len() < 40].shape\n",
    "\n",
    "# No sequences with length < 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3186, 16)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Additionally they mention in $2.3.5: To decrease the training time, the maximum protein length was 1000\n",
    "df[df['Sequence'].str.len() > 1000].shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that 3186 samples have to be truncated. We do this as they suggest, by taking out amino-acids in the center of the sequence.\n",
    "\n",
    "Finally, amino acids shorter than length 1000 must be padded to length 1000. Additionally, a mask must be generated to ensure the attention mechanism ignores padding.\n",
    "\n",
    "Note: Only in the description of Figure 3 is it mentioned that for *visualization* the amino acids are padded from the middle. We assume this to be the case all the time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 1000\n",
    "PAD_CHAR = '-'\n",
    "\n",
    "# Remove the center of the sequence, keeping the first and last 500.\n",
    "def truncate_sequence(seq, max_len=1000):\n",
    "    if len(seq) <= max_len:\n",
    "        return seq\n",
    "    half = max_len // 2\n",
    "    return seq[:half] + seq[-half:]\n",
    "\n",
    "# Pad the sequence in the center with a specified character\n",
    "def pad_middle(seq, max_len=MAX_LEN, pad_char=PAD_CHAR):\n",
    "    pad_total = max_len - len(seq)\n",
    "    half_idx = len(seq) // 2\n",
    "    pad_left = pad_total // 2\n",
    "    pad_right = pad_total - pad_left\n",
    "    return seq[:half_idx] + (pad_char * pad_left) + seq[half_idx:] + (pad_char * pad_right)\n",
    "\n",
    "# Prepare the sequence for the the processed training dataset\n",
    "def prepare_sequence(seq, max_len=MAX_LEN, pad_char=PAD_CHAR):\n",
    "    if len(seq) > max_len:\n",
    "        return truncate_sequence(seq, max_len)\n",
    "    elif len(seq) < max_len:\n",
    "        return pad_middle(seq, max_len, pad_char)\n",
    "    else:\n",
    "        return seq  # already length 1000\n",
    "\n",
    "# Generate a mask for the sequence\n",
    "def generate_mask(seq, pad_char='X'):\n",
    "    \"\"\" The mask is a string of 0s and 1s, where 1 indicates the presence of an amino acid and 0 indicates a padding character \"\"\"\n",
    "    return ''.join(['0' if aa == pad_char else '1' for aa in seq])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\neere\\AppData\\Local\\Temp\\ipykernel_5396\\1970824193.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['PaddedSequence'] = df_filtered['Sequence'].apply(prepare_sequence)\n",
      "C:\\Users\\neere\\AppData\\Local\\Temp\\ipykernel_5396\\1970824193.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['Mask'] = df_filtered['PaddedSequence'].apply(generate_mask)\n"
     ]
    }
   ],
   "source": [
    "# Create a new column with truncated sequences\n",
    "df_filtered['PaddedSequence'] = df_filtered['Sequence'].apply(prepare_sequence)\n",
    "df_filtered['Mask'] = df_filtered['PaddedSequence'].apply(generate_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to a new CSV\n",
    "df_filtered.to_csv(train_path, index=False)\n",
    "# Filter by partition\n",
    "df_train = df_filtered[df_filtered['Partition'] != 4]  # Partitions 0â€“3 for training/validation\n",
    "df_test = df_filtered[df_filtered['Partition'] == 4]       # Partition 4 for testing\n",
    "\n",
    "# Save to separate CSV files\n",
    "df_train.to_csv(train_path, index=False)\n",
    "df_test.to_csv(test_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 18)\n",
      "(17351, 18)\n",
      "(17351, 18)\n",
      "(17351, 18)\n"
     ]
    }
   ],
   "source": [
    "df_processed = pd.read_csv(train_path, delimiter=',')\n",
    "print(df_processed[df_processed['Sequence'].str.len() == 1000].shape)\n",
    "print(df_processed[df_processed['PaddedSequence'].str.len() == 1000].shape)\n",
    "print(df_processed[df_processed['Mask'].str.len() == 1000].shape)\n",
    "print(df_processed.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Converting the sequence to a feature vector using BLOSUM-62"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLOSUM(62, default=0, {'A': defaultdict(<function BLOSUM.__init__.<locals>.<lambda> at 0x0000021214ACBB50>, {'A': 4.0, 'R': -1.0, 'N': -2.0, 'D': -2.0, 'C': 0.0, 'Q': -1.0, 'E': -1.0, 'G': 0.0, 'H': -2.0, 'I': -1.0, 'L': -1.0, 'K': -1.0, 'M': -1.0, 'F': -2.0, 'P': -1.0, 'S': 1.0, 'T': 0.0, 'W': -3.0, 'Y': -2.0, 'V': 0.0, 'B': -2.0, 'J': -1.0, 'Z': -1.0, 'X': -1.0, '*': -4.0}), 'R': defaultdict(<function BLOSUM.__init__.<locals>.<lambda> at 0x0000021214ACB880>, {'A': -1.0, 'R': 5.0, 'N': 0.0, 'D': -2.0, 'C': -3.0, 'Q': 1.0, 'E': 0.0, 'G': -2.0, 'H': 0.0, 'I': -3.0, 'L': -2.0, 'K': 2.0, 'M': -1.0, 'F': -3.0, 'P': -2.0, 'S': -1.0, 'T': -1.0, 'W': -3.0, 'Y': -2.0, 'V': -3.0, 'B': -1.0, 'J': -2.0, 'Z': 0.0, 'X': -1.0, '*': -4.0}), 'N': defaultdict(<function BLOSUM.__init__.<locals>.<lambda> at 0x0000021218746CB0>, {'A': -2.0, 'R': 0.0, 'N': 6.0, 'D': 1.0, 'C': -3.0, 'Q': 0.0, 'E': 0.0, 'G': 0.0, 'H': 1.0, 'I': -3.0, 'L': -3.0, 'K': 0.0, 'M': -2.0, 'F': -3.0, 'P': -2.0, 'S': 1.0, 'T': 0.0, 'W': -4.0, 'Y': -2.0, 'V': -3.0, 'B': 4.0, 'J': -3.0, 'Z': 0.0, 'X': -1.0, '*': -4.0}), 'D': defaultdict(<function BLOSUM.__init__.<locals>.<lambda> at 0x0000021214405F30>, {'A': -2.0, 'R': -2.0, 'N': 1.0, 'D': 6.0, 'C': -3.0, 'Q': 0.0, 'E': 2.0, 'G': -1.0, 'H': -1.0, 'I': -3.0, 'L': -4.0, 'K': -1.0, 'M': -3.0, 'F': -3.0, 'P': -1.0, 'S': 0.0, 'T': -1.0, 'W': -4.0, 'Y': -3.0, 'V': -3.0, 'B': 4.0, 'J': -3.0, 'Z': 1.0, 'X': -1.0, '*': -4.0}), 'C': defaultdict(<function BLOSUM.__init__.<locals>.<lambda> at 0x00000212144060E0>, {'A': 0.0, 'R': -3.0, 'N': -3.0, 'D': -3.0, 'C': 9.0, 'Q': -3.0, 'E': -4.0, 'G': -3.0, 'H': -3.0, 'I': -1.0, 'L': -1.0, 'K': -3.0, 'M': -1.0, 'F': -2.0, 'P': -3.0, 'S': -1.0, 'T': -1.0, 'W': -2.0, 'Y': -2.0, 'V': -1.0, 'B': -3.0, 'J': -1.0, 'Z': -3.0, 'X': -1.0, '*': -4.0}), 'Q': defaultdict(<function BLOSUM.__init__.<locals>.<lambda> at 0x0000021214406170>, {'A': -1.0, 'R': 1.0, 'N': 0.0, 'D': 0.0, 'C': -3.0, 'Q': 5.0, 'E': 2.0, 'G': -2.0, 'H': 0.0, 'I': -3.0, 'L': -2.0, 'K': 1.0, 'M': 0.0, 'F': -3.0, 'P': -1.0, 'S': 0.0, 'T': -1.0, 'W': -2.0, 'Y': -1.0, 'V': -2.0, 'B': 0.0, 'J': -2.0, 'Z': 4.0, 'X': -1.0, '*': -4.0}), 'E': defaultdict(<function BLOSUM.__init__.<locals>.<lambda> at 0x0000021214406200>, {'A': -1.0, 'R': 0.0, 'N': 0.0, 'D': 2.0, 'C': -4.0, 'Q': 2.0, 'E': 5.0, 'G': -2.0, 'H': 0.0, 'I': -3.0, 'L': -3.0, 'K': 1.0, 'M': -2.0, 'F': -3.0, 'P': -1.0, 'S': 0.0, 'T': -1.0, 'W': -3.0, 'Y': -2.0, 'V': -2.0, 'B': 1.0, 'J': -3.0, 'Z': 4.0, 'X': -1.0, '*': -4.0}), 'G': defaultdict(<function BLOSUM.__init__.<locals>.<lambda> at 0x0000021214406290>, {'A': 0.0, 'R': -2.0, 'N': 0.0, 'D': -1.0, 'C': -3.0, 'Q': -2.0, 'E': -2.0, 'G': 6.0, 'H': -2.0, 'I': -4.0, 'L': -4.0, 'K': -2.0, 'M': -3.0, 'F': -3.0, 'P': -2.0, 'S': 0.0, 'T': -2.0, 'W': -2.0, 'Y': -3.0, 'V': -3.0, 'B': -1.0, 'J': -4.0, 'Z': -2.0, 'X': -1.0, '*': -4.0}), 'H': defaultdict(<function BLOSUM.__init__.<locals>.<lambda> at 0x0000021214406320>, {'A': -2.0, 'R': 0.0, 'N': 1.0, 'D': -1.0, 'C': -3.0, 'Q': 0.0, 'E': 0.0, 'G': -2.0, 'H': 8.0, 'I': -3.0, 'L': -3.0, 'K': -1.0, 'M': -2.0, 'F': -1.0, 'P': -2.0, 'S': -1.0, 'T': -2.0, 'W': -2.0, 'Y': 2.0, 'V': -3.0, 'B': 0.0, 'J': -3.0, 'Z': 0.0, 'X': -1.0, '*': -4.0}), 'I': defaultdict(<function BLOSUM.__init__.<locals>.<lambda> at 0x00000212144063B0>, {'A': -1.0, 'R': -3.0, 'N': -3.0, 'D': -3.0, 'C': -1.0, 'Q': -3.0, 'E': -3.0, 'G': -4.0, 'H': -3.0, 'I': 4.0, 'L': 2.0, 'K': -3.0, 'M': 1.0, 'F': 0.0, 'P': -3.0, 'S': -2.0, 'T': -1.0, 'W': -3.0, 'Y': -1.0, 'V': 3.0, 'B': -3.0, 'J': 3.0, 'Z': -3.0, 'X': -1.0, '*': -4.0}), 'L': defaultdict(<function BLOSUM.__init__.<locals>.<lambda> at 0x0000021214406440>, {'A': -1.0, 'R': -2.0, 'N': -3.0, 'D': -4.0, 'C': -1.0, 'Q': -2.0, 'E': -3.0, 'G': -4.0, 'H': -3.0, 'I': 2.0, 'L': 4.0, 'K': -2.0, 'M': 2.0, 'F': 0.0, 'P': -3.0, 'S': -2.0, 'T': -1.0, 'W': -2.0, 'Y': -1.0, 'V': 1.0, 'B': -4.0, 'J': 3.0, 'Z': -3.0, 'X': -1.0, '*': -4.0}), 'K': defaultdict(<function BLOSUM.__init__.<locals>.<lambda> at 0x00000212144064D0>, {'A': -1.0, 'R': 2.0, 'N': 0.0, 'D': -1.0, 'C': -3.0, 'Q': 1.0, 'E': 1.0, 'G': -2.0, 'H': -1.0, 'I': -3.0, 'L': -2.0, 'K': 5.0, 'M': -1.0, 'F': -3.0, 'P': -1.0, 'S': 0.0, 'T': -1.0, 'W': -3.0, 'Y': -2.0, 'V': -2.0, 'B': 0.0, 'J': -3.0, 'Z': 1.0, 'X': -1.0, '*': -4.0}), 'M': defaultdict(<function BLOSUM.__init__.<locals>.<lambda> at 0x0000021214406560>, {'A': -1.0, 'R': -1.0, 'N': -2.0, 'D': -3.0, 'C': -1.0, 'Q': 0.0, 'E': -2.0, 'G': -3.0, 'H': -2.0, 'I': 1.0, 'L': 2.0, 'K': -1.0, 'M': 5.0, 'F': 0.0, 'P': -2.0, 'S': -1.0, 'T': -1.0, 'W': -1.0, 'Y': -1.0, 'V': 1.0, 'B': -3.0, 'J': 2.0, 'Z': -1.0, 'X': -1.0, '*': -4.0}), 'F': defaultdict(<function BLOSUM.__init__.<locals>.<lambda> at 0x00000212144065F0>, {'A': -2.0, 'R': -3.0, 'N': -3.0, 'D': -3.0, 'C': -2.0, 'Q': -3.0, 'E': -3.0, 'G': -3.0, 'H': -1.0, 'I': 0.0, 'L': 0.0, 'K': -3.0, 'M': 0.0, 'F': 6.0, 'P': -4.0, 'S': -2.0, 'T': -2.0, 'W': 1.0, 'Y': 3.0, 'V': -1.0, 'B': -3.0, 'J': 0.0, 'Z': -3.0, 'X': -1.0, '*': -4.0}), 'P': defaultdict(<function BLOSUM.__init__.<locals>.<lambda> at 0x0000021214406680>, {'A': -1.0, 'R': -2.0, 'N': -2.0, 'D': -1.0, 'C': -3.0, 'Q': -1.0, 'E': -1.0, 'G': -2.0, 'H': -2.0, 'I': -3.0, 'L': -3.0, 'K': -1.0, 'M': -2.0, 'F': -4.0, 'P': 7.0, 'S': -1.0, 'T': -1.0, 'W': -4.0, 'Y': -3.0, 'V': -2.0, 'B': -2.0, 'J': -3.0, 'Z': -1.0, 'X': -1.0, '*': -4.0}), 'S': defaultdict(<function BLOSUM.__init__.<locals>.<lambda> at 0x0000021214406710>, {'A': 1.0, 'R': -1.0, 'N': 1.0, 'D': 0.0, 'C': -1.0, 'Q': 0.0, 'E': 0.0, 'G': 0.0, 'H': -1.0, 'I': -2.0, 'L': -2.0, 'K': 0.0, 'M': -1.0, 'F': -2.0, 'P': -1.0, 'S': 4.0, 'T': 1.0, 'W': -3.0, 'Y': -2.0, 'V': -2.0, 'B': 0.0, 'J': -2.0, 'Z': 0.0, 'X': -1.0, '*': -4.0}), 'T': defaultdict(<function BLOSUM.__init__.<locals>.<lambda> at 0x00000212144067A0>, {'A': 0.0, 'R': -1.0, 'N': 0.0, 'D': -1.0, 'C': -1.0, 'Q': -1.0, 'E': -1.0, 'G': -2.0, 'H': -2.0, 'I': -1.0, 'L': -1.0, 'K': -1.0, 'M': -1.0, 'F': -2.0, 'P': -1.0, 'S': 1.0, 'T': 5.0, 'W': -2.0, 'Y': -2.0, 'V': 0.0, 'B': -1.0, 'J': -1.0, 'Z': -1.0, 'X': -1.0, '*': -4.0}), 'W': defaultdict(<function BLOSUM.__init__.<locals>.<lambda> at 0x0000021214406830>, {'A': -3.0, 'R': -3.0, 'N': -4.0, 'D': -4.0, 'C': -2.0, 'Q': -2.0, 'E': -3.0, 'G': -2.0, 'H': -2.0, 'I': -3.0, 'L': -2.0, 'K': -3.0, 'M': -1.0, 'F': 1.0, 'P': -4.0, 'S': -3.0, 'T': -2.0, 'W': 11.0, 'Y': 2.0, 'V': -3.0, 'B': -4.0, 'J': -2.0, 'Z': -2.0, 'X': -1.0, '*': -4.0}), 'Y': defaultdict(<function BLOSUM.__init__.<locals>.<lambda> at 0x00000212144068C0>, {'A': -2.0, 'R': -2.0, 'N': -2.0, 'D': -3.0, 'C': -2.0, 'Q': -1.0, 'E': -2.0, 'G': -3.0, 'H': 2.0, 'I': -1.0, 'L': -1.0, 'K': -2.0, 'M': -1.0, 'F': 3.0, 'P': -3.0, 'S': -2.0, 'T': -2.0, 'W': 2.0, 'Y': 7.0, 'V': -1.0, 'B': -3.0, 'J': -1.0, 'Z': -2.0, 'X': -1.0, '*': -4.0}), 'V': defaultdict(<function BLOSUM.__init__.<locals>.<lambda> at 0x0000021214406950>, {'A': 0.0, 'R': -3.0, 'N': -3.0, 'D': -3.0, 'C': -1.0, 'Q': -2.0, 'E': -2.0, 'G': -3.0, 'H': -3.0, 'I': 3.0, 'L': 1.0, 'K': -2.0, 'M': 1.0, 'F': -1.0, 'P': -2.0, 'S': -2.0, 'T': 0.0, 'W': -3.0, 'Y': -1.0, 'V': 4.0, 'B': -3.0, 'J': 2.0, 'Z': -2.0, 'X': -1.0, '*': -4.0}), 'B': defaultdict(<function BLOSUM.__init__.<locals>.<lambda> at 0x00000212144069E0>, {'A': -2.0, 'R': -1.0, 'N': 4.0, 'D': 4.0, 'C': -3.0, 'Q': 0.0, 'E': 1.0, 'G': -1.0, 'H': 0.0, 'I': -3.0, 'L': -4.0, 'K': 0.0, 'M': -3.0, 'F': -3.0, 'P': -2.0, 'S': 0.0, 'T': -1.0, 'W': -4.0, 'Y': -3.0, 'V': -3.0, 'B': 4.0, 'J': -3.0, 'Z': 0.0, 'X': -1.0, '*': -4.0}), 'J': defaultdict(<function BLOSUM.__init__.<locals>.<lambda> at 0x0000021214406A70>, {'A': -1.0, 'R': -2.0, 'N': -3.0, 'D': -3.0, 'C': -1.0, 'Q': -2.0, 'E': -3.0, 'G': -4.0, 'H': -3.0, 'I': 3.0, 'L': 3.0, 'K': -3.0, 'M': 2.0, 'F': 0.0, 'P': -3.0, 'S': -2.0, 'T': -1.0, 'W': -2.0, 'Y': -1.0, 'V': 2.0, 'B': -3.0, 'J': 3.0, 'Z': -3.0, 'X': -1.0, '*': -4.0}), 'Z': defaultdict(<function BLOSUM.__init__.<locals>.<lambda> at 0x0000021214406B00>, {'A': -1.0, 'R': 0.0, 'N': 0.0, 'D': 1.0, 'C': -3.0, 'Q': 4.0, 'E': 4.0, 'G': -2.0, 'H': 0.0, 'I': -3.0, 'L': -3.0, 'K': 1.0, 'M': -1.0, 'F': -3.0, 'P': -1.0, 'S': 0.0, 'T': -1.0, 'W': -2.0, 'Y': -2.0, 'V': -2.0, 'B': 0.0, 'J': -3.0, 'Z': 4.0, 'X': -1.0, '*': -4.0}), 'X': defaultdict(<function BLOSUM.__init__.<locals>.<lambda> at 0x0000021214406B90>, {'A': -1.0, 'R': -1.0, 'N': -1.0, 'D': -1.0, 'C': -1.0, 'Q': -1.0, 'E': -1.0, 'G': -1.0, 'H': -1.0, 'I': -1.0, 'L': -1.0, 'K': -1.0, 'M': -1.0, 'F': -1.0, 'P': -1.0, 'S': -1.0, 'T': -1.0, 'W': -1.0, 'Y': -1.0, 'V': -1.0, 'B': -1.0, 'J': -1.0, 'Z': -1.0, 'X': -1.0, '*': -4.0}), '*': defaultdict(<function BLOSUM.__init__.<locals>.<lambda> at 0x0000021214406C20>, {'A': -4.0, 'R': -4.0, 'N': -4.0, 'D': -4.0, 'C': -4.0, 'Q': -4.0, 'E': -4.0, 'G': -4.0, 'H': -4.0, 'I': -4.0, 'L': -4.0, 'K': -4.0, 'M': -4.0, 'F': -4.0, 'P': -4.0, 'S': -4.0, 'T': -4.0, 'W': -4.0, 'Y': -4.0, 'V': -4.0, 'B': -4.0, 'J': -4.0, 'Z': -4.0, 'X': -4.0, '*': 1.0})}\n",
      "['A', 'R', 'N', 'D', 'C', 'Q', 'E', 'G', 'H', 'I', 'L', 'K', 'M', 'F', 'P', 'S', 'T', 'W', 'Y', 'V', 'B', 'J', 'Z', 'X', '*']\n",
      "25\n"
     ]
    }
   ],
   "source": [
    "matrix = bl.BLOSUM(62, default=0)\n",
    "print(matrix)\n",
    "\n",
    "# Get all the keys in the dictionary and convert them to a list\n",
    "matrix_keys = list(matrix.keys())\n",
    "\n",
    "print(matrix_keys)\n",
    "print(len(matrix_keys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "['A', 'R', 'N', 'D', 'C', 'Q', 'E', 'G', 'H', 'I', 'L', 'K', 'M', 'F', 'P', 'S', 'T', 'W', 'Y', 'V']\n"
     ]
    }
   ],
   "source": [
    "# Remove B, Z, X, J, * from the keys list as they are not standard amino acids and DeepLoc 1.0 only has 20 features.\n",
    "matrix_keys = [key for key in matrix_keys if key not in ['B', 'Z', 'X', 'J', '*']]\n",
    "print(len(matrix_keys))\n",
    "print(matrix_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_sequence_with_blosum(seq):\n",
    "    \"\"\"\n",
    "    Encode a sequence using BLOSUM62, applying the mask.\n",
    "    Returns: (max_len x 20) numpy array\n",
    "    \"\"\"\n",
    "    encoded = np.zeros((MAX_LEN, len(matrix_keys)), dtype=np.float32)\n",
    "    for i, aa in enumerate(seq):\n",
    "        encoded[i] = [matrix[aa][other_aa] for other_aa in matrix_keys]\n",
    "        # We ensured the default was 0, so no need to use the mask.\n",
    "    return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4. -1. -2. ... -3. -2.  0.]\n",
      " [ 0. -3. -3. ... -2. -2. -1.]\n",
      " [-2. -2.  1. ... -4. -3. -3.]\n",
      " ...\n",
      " [ 0.  0.  0. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ...  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "# Test the encoding function\n",
    "features = encode_sequence_with_blosum(\"ACDXYZ--\")\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Creating a dataset which encodes sequences & returns batches for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom dataset class for DeepLoc\n",
    "class DeepLocDataset(Dataset):\n",
    "    def __init__(self, df, label_columns, matrix):\n",
    "        self.sequences = df['PaddedSequence'].values # Fetch the processed sequences\n",
    "        self.masks = df['Mask'].values # Fetch the masks\n",
    "        self.labels = df[label_columns].values.astype(np.float32) # Convert labels to float32\n",
    "        self.matrix = matrix # BLOSUM matrix\n",
    "        self.max_len = MAX_LEN\n",
    "        self.matrix_keys = list(matrix.keys())\n",
    "        self.matrix_keys = [key for key in self.matrix_keys if key not in ['B', 'Z', 'X', 'J', '*']]\n",
    "        self.num_features = len(self.matrix_keys)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq = self.sequences[idx]\n",
    "        mask = self.masks[idx]\n",
    "        label = self.labels[idx]\n",
    "        encoded_seq = encode_sequence_with_blosum(seq)\n",
    "        mask_tensor = torch.tensor([int(m) for m in mask], dtype=torch.float32)\n",
    "        return torch.tensor(encoded_seq), torch.tensor(label), mask_tensor # Return the encoded sequence, label, and mask tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dataset and DataLoader\n",
    "dataset = DeepLocDataset(df_filtered, location_columns, matrix)\n",
    "loader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_batch shape: torch.Size([32, 1000, 20])\n",
      "y_batch shape: torch.Size([32, 10])\n",
      "mask_batch shape: torch.Size([32, 1000])\n"
     ]
    }
   ],
   "source": [
    "# Test the DataLoader\n",
    "for x_batch, y_batch, mask_batch in loader:\n",
    "    print(\"x_batch shape:\", x_batch.shape) # x_batch: (B, 1000, 20)\n",
    "    print(\"y_batch shape:\", y_batch.shape) # y_batch: (B, 10)\n",
    "    print(\"mask_batch shape:\", mask_batch.shape) # mask_batch: (B, 1000)\n",
    "    break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepLoc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
