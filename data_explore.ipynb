{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DeepLoc EDA\n",
    "In this file we explore and preprocess the datasets published by HTU for the different version of DeepLoc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library imports\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import blosum as bl\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DeepLoc 1.0 Dataset\n",
    "We explore the dataset published on the [HTU website](https://services.healthtech.dtu.dk/services/DeepLoc-1.0/). The dataset in the GitHub repo is incomplete, with ~40% less data than the dataset mentioned in their paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DeepLoc 1.0 EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data file for the original DeepLoc 1.0 dataset\n",
    "fasta_file_path = './data/DeepLoc1.0/deeploc1.0.fasta'\n",
    "\n",
    "# File paths for the processed csv used for training and testing\n",
    "train_path = './data/DeepLoc1.0/deeploc1.0-train.csv'\n",
    "test_path = './data/DeepLoc1.0/deeploc1.0-test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the localizations as found in the fasta file and their desired mapping.\n",
    "location_categories = {\n",
    "    \"Nucleus\": [\"Nucleus\"],\n",
    "    \"Cytoplasm\": [\"Cytoplasm\"],\n",
    "    \"Extracellular\": [\"Extracellular\"],\n",
    "    \"Mitochondrion\": [\"Mitochondrion\"],\n",
    "    \"Cell membrane\": [\"Cell.membrane\"],\n",
    "    \"Endoplasmic reticulum\": [\"Endoplasmic.reticulum\"],\n",
    "    \"Plastid\": [\"Plastid\"],\n",
    "    \"Golgi apparatus\": [\"Golgi.apparatus\"],\n",
    "    \"Lysosome/Vacuole\": [\"Lysosome/Vacuole\"],\n",
    "    \"Peroxisome\": [\"Peroxisome\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the locations for the sequence\n",
    "def normalize_location(header_line):\n",
    "    header_line = header_line.lower()\n",
    "    matches = set()\n",
    "    for category, keywords in location_categories.items():\n",
    "        for keyword in keywords:\n",
    "            if keyword.lower() in header_line: # Normalize, just in case.\n",
    "                matches.add(category)\n",
    "    return matches\n",
    "\n",
    "# Count the number of sequences for each location\n",
    "def count_locations(fasta_file_path):\n",
    "    location_counts = defaultdict(int)\n",
    "    with open(fasta_file_path, 'r') as fasta_file:\n",
    "        for line in fasta_file:\n",
    "            if line.startswith('>'):\n",
    "                matched_categories = normalize_location(line)\n",
    "                for category in matched_categories:\n",
    "                    location_counts[category] += 1\n",
    "    return location_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: This still allows one sequence to have multiple locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Location counts:\n",
      "Nucleus: 4189\n",
      "Cytoplasm: 2688\n",
      "Extracellular: 1973\n",
      "Mitochondrion: 1510\n",
      "Cell membrane: 1340\n",
      "Endoplasmic reticulum: 862\n",
      "Plastid: 757\n",
      "Golgi apparatus: 356\n",
      "Lysosome/Vacuole: 321\n",
      "Peroxisome: 154\n"
     ]
    }
   ],
   "source": [
    "location_counts = count_locations(fasta_file_path)\n",
    "\n",
    "# Print the counts for each location\n",
    "print(\"Location counts:\")\n",
    "for location in location_categories:\n",
    "    print(f\"{location}: {location_counts[location]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now count only the sequences which have at most one localization in the dataset.\n",
    "> Note: All the sequences with more than one localization had the following localizations: Nucleus and Cytoplasm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of sequences that only have one location\n",
    "def count_single_location_only(fasta_file_path):\n",
    "    location_counts = defaultdict(int)\n",
    "    with open(fasta_file_path, 'r') as fasta_file:\n",
    "        for line in fasta_file:\n",
    "            if line.startswith('>'):\n",
    "                matched_categories = normalize_location(line)\n",
    "                if len(matched_categories) == 1:\n",
    "                    category = next(iter(matched_categories))\n",
    "                    location_counts[category] += 1\n",
    "    return location_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Location counts:\n",
      "Nucleus: 4043\n",
      "Cytoplasm: 2542\n",
      "Extracellular: 1973\n",
      "Mitochondrion: 1510\n",
      "Cell membrane: 1340\n",
      "Endoplasmic reticulum: 862\n",
      "Plastid: 757\n",
      "Golgi apparatus: 356\n",
      "Lysosome/Vacuole: 321\n",
      "Peroxisome: 154\n",
      "Total: 13858\n"
     ]
    }
   ],
   "source": [
    "location_counts = count_single_location_only(fasta_file_path)\n",
    "total_count = 0\n",
    "# Print the counts for each location\n",
    "print(\"Location counts:\")\n",
    "for location in location_categories:\n",
    "    total_count += location_counts[location]\n",
    "    print(f\"{location}: {location_counts[location]}\")\n",
    "print(f\"Total: {total_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We see that we end up with a total of 13858 sequences, this is exactly the same amount as in DeepLoc 1.0 (As per Section 2.3.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will convert the fasta file to a pandas dataframe\n",
    "# The dataframe will have the following columns:\n",
    "# - sequence: the protein sequence\n",
    "# - Membrane: 1 if the protein is a membrane protein, 0 otherwise\n",
    "# - test: 1 if the protein is a test protein, 0 otherwise\n",
    "# - location: the location of the protein (e.g. Nucleus, Cytoplasm, etc.) in one-hot encoding\n",
    "\n",
    "def fasta_to_dataframe(fasta_file_path):\n",
    "    rows = []\n",
    "    current_header = \"\"\n",
    "    current_seq = \"\"\n",
    "\n",
    "    with open(fasta_file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line.startswith('>'):\n",
    "                if current_header and current_seq:\n",
    "                    row = parse_fasta_entry(current_header, current_seq)\n",
    "                    if row:\n",
    "                        rows.append(row)\n",
    "                current_header = line\n",
    "                current_seq = \"\"\n",
    "            else:\n",
    "                current_seq += line\n",
    "\n",
    "        # Save last entry\n",
    "        if current_header and current_seq:\n",
    "            row = parse_fasta_entry(current_header, current_seq)\n",
    "            if row:\n",
    "                rows.append(row)\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    return df\n",
    "\n",
    "\n",
    "def parse_fasta_entry(header, sequence):\n",
    "    \"\"\" Parse a single FASTA entry and return a dictionary with relevant information per entry if the location is valid. \"\"\"\n",
    "    # Check if the header contains a valid location\n",
    "    location = extract_single_location(header)\n",
    "    if location is None:\n",
    "        return None  # Skip if no valid or ambiguous location\n",
    "\n",
    "    is_membrane = \"-M\" in header\n",
    "    is_test = \"test\" in header.lower()\n",
    "\n",
    "    row = {\n",
    "        \"Sequence\": sequence,\n",
    "        \"Membrane\": int(is_membrane),\n",
    "        \"test\": is_test\n",
    "    }\n",
    "\n",
    "    # One-hot encoding of location\n",
    "    for cat in location_categories.keys():\n",
    "        row[cat] = int(cat == location)\n",
    "\n",
    "    return row\n",
    "\n",
    "\n",
    "def extract_single_location(header):\n",
    "    \"\"\" Extract a single location from the header. If more than one location is found, return None.\"\"\"\n",
    "    matched = []\n",
    "\n",
    "    for category, substrings in location_categories.items():\n",
    "        for s in substrings:\n",
    "            if s in header:\n",
    "                matched.append(category)\n",
    "                break  # Only match once per category\n",
    "\n",
    "    if len(matched) == 1:\n",
    "        return matched[0]  # Return only if there's exactly one match\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            Sequence  Membrane   test  \\\n",
      "0  MGLPVSWAPPALWVLGCCALLLSLWALCTACRRPEDAVAPRKRARR...         1   True   \n",
      "1  MEVLEEPAPGPGGADAAERRGLRRLLLSGFQEELRALLVLAGPAFL...         1  False   \n",
      "2  MMKTLSSGNCTLNVPAKNSYRMVVLGASRVGKSSIVSRFLNGRFED...         1  False   \n",
      "3  MAKRTFSNLETFLIFLLVMMSAITVALLSLLFITSGTIENHKDLGG...         1  False   \n",
      "4  MGNCQAGHNLHLCLAHHPPLVCATLILLLLGLSGLGLGSFLLTHRT...         1  False   \n",
      "\n",
      "   Nucleus  Cytoplasm  Extracellular  Mitochondrion  Cell membrane  \\\n",
      "0        0          0              0              0              1   \n",
      "1        0          0              0              0              1   \n",
      "2        0          0              0              0              1   \n",
      "3        0          0              0              0              1   \n",
      "4        0          0              0              0              1   \n",
      "\n",
      "   Endoplasmic reticulum  Plastid  Golgi apparatus  Lysosome/Vacuole  \\\n",
      "0                      0        0                0                 0   \n",
      "1                      0        0                0                 0   \n",
      "2                      0        0                0                 0   \n",
      "3                      0        0                0                 0   \n",
      "4                      0        0                0                 0   \n",
      "\n",
      "   Peroxisome  \n",
      "0           0  \n",
      "1           0  \n",
      "2           0  \n",
      "3           0  \n",
      "4           0  \n"
     ]
    }
   ],
   "source": [
    "# Examine the first few rows of the newly created dataframe\n",
    "df = fasta_to_dataframe(fasta_file_path)\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sequences: 13858\n"
     ]
    }
   ],
   "source": [
    "# We verify that the dataframe has the correct number of rows\n",
    "total_sequences = df.shape[0]\n",
    "print(f\"Total sequences: {total_sequences}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note: In the paper, the authors mention that 9,98% of the sequences had length longer than 1000 and had to be truncated. We found that this is most likely a typo as the actual number is 9,907%\n",
    "> \n",
    "> The authors mention nothing of the ~90% sequences that are shorter than 1000, yet the plots in their paper do not show any sequences shorter than 1000. We follow their approach and pad the sequences from the middle, and generate masks for the attention mechanism. The authors only mention this padding in Figure 3 and nowhere else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sequences shorter than 1000: 12481\n"
     ]
    }
   ],
   "source": [
    "# 90 % of sequences are shorter than 1000\n",
    "# 9,907 sequences are longer than 1000\n",
    "def count_short_sequences(df, max_len=1000):\n",
    "    return df['Sequence'].str.len().lt(max_len).sum()\n",
    "short_count = count_short_sequences(df)\n",
    "print(f\"Number of sequences shorter than 1000: {short_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 1000\n",
    "PAD_CHAR = '-'\n",
    "\n",
    "# Remove the center of the sequence, keeping the first and last 500.\n",
    "def truncate_sequence(seq, max_len=1000):\n",
    "    if len(seq) <= max_len:\n",
    "        return seq\n",
    "    half = max_len // 2\n",
    "    return seq[:half] + seq[-half:]\n",
    "\n",
    "# Pad the sequence in the center with a specified character\n",
    "def pad_middle(seq, max_len=MAX_LEN, pad_char=PAD_CHAR):\n",
    "    pad_total = max_len - len(seq)\n",
    "    half_idx = len(seq) // 2\n",
    "    return seq[:half_idx] + (pad_char * pad_total) + seq[half_idx:] \n",
    "\n",
    "# Prepare the sequence for the the processed training dataset\n",
    "def prepare_sequence(seq, max_len=MAX_LEN, pad_char=PAD_CHAR):\n",
    "    if len(seq) > max_len:\n",
    "        return truncate_sequence(seq, max_len)\n",
    "    elif len(seq) < max_len:\n",
    "        return pad_middle(seq, max_len, pad_char)\n",
    "    else:\n",
    "        return seq  # already length 1000\n",
    "\n",
    "# Generate a mask for the sequence\n",
    "def generate_mask(seq, pad_char=PAD_CHAR):\n",
    "    \"\"\" The mask is a string of 0s and 1s, where 1 indicates the presence of an amino acid and 0 indicates a padding character \"\"\"\n",
    "    return ''.join(['0' if aa == pad_char else '1' for aa in seq])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column with truncated sequences\n",
    "df['PaddedSequence'] = df['Sequence'].apply(prepare_sequence)\n",
    "df['Mask'] = df['PaddedSequence'].apply(generate_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13858, 15)\n"
     ]
    }
   ],
   "source": [
    "print(df[df['PaddedSequence'].str.len() == 1000].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sequence</th>\n",
       "      <th>Membrane</th>\n",
       "      <th>test</th>\n",
       "      <th>Nucleus</th>\n",
       "      <th>Cytoplasm</th>\n",
       "      <th>Extracellular</th>\n",
       "      <th>Mitochondrion</th>\n",
       "      <th>Cell membrane</th>\n",
       "      <th>Endoplasmic reticulum</th>\n",
       "      <th>Plastid</th>\n",
       "      <th>Golgi apparatus</th>\n",
       "      <th>Lysosome/Vacuole</th>\n",
       "      <th>Peroxisome</th>\n",
       "      <th>PaddedSequence</th>\n",
       "      <th>Mask</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MGLPVSWAPPALWVLGCCALLLSLWALCTACRRPEDAVAPRKRARR...</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>MGLPVSWAPPALWVLGCCALLLSLWALCTACRRPEDAVAPRKRARR...</td>\n",
       "      <td>1111111111111111111111111111111111111111111111...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MEVLEEPAPGPGGADAAERRGLRRLLLSGFQEELRALLVLAGPAFL...</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>MEVLEEPAPGPGGADAAERRGLRRLLLSGFQEELRALLVLAGPAFL...</td>\n",
       "      <td>1111111111111111111111111111111111111111111111...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MMKTLSSGNCTLNVPAKNSYRMVVLGASRVGKSSIVSRFLNGRFED...</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>MMKTLSSGNCTLNVPAKNSYRMVVLGASRVGKSSIVSRFLNGRFED...</td>\n",
       "      <td>1111111111111111111111111111111111111111111111...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MAKRTFSNLETFLIFLLVMMSAITVALLSLLFITSGTIENHKDLGG...</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>MAKRTFSNLETFLIFLLVMMSAITVALLSLLFITSGTIENHKDLGG...</td>\n",
       "      <td>1111111111111111111111111111111111111111111111...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MGNCQAGHNLHLCLAHHPPLVCATLILLLLGLSGLGLGSFLLTHRT...</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>MGNCQAGHNLHLCLAHHPPLVCATLILLLLGLSGLGLGSFLLTHRT...</td>\n",
       "      <td>1111111111111111111111111111111111111111111111...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sequence  Membrane   test  \\\n",
       "0  MGLPVSWAPPALWVLGCCALLLSLWALCTACRRPEDAVAPRKRARR...         1   True   \n",
       "1  MEVLEEPAPGPGGADAAERRGLRRLLLSGFQEELRALLVLAGPAFL...         1  False   \n",
       "2  MMKTLSSGNCTLNVPAKNSYRMVVLGASRVGKSSIVSRFLNGRFED...         1  False   \n",
       "3  MAKRTFSNLETFLIFLLVMMSAITVALLSLLFITSGTIENHKDLGG...         1  False   \n",
       "4  MGNCQAGHNLHLCLAHHPPLVCATLILLLLGLSGLGLGSFLLTHRT...         1  False   \n",
       "\n",
       "   Nucleus  Cytoplasm  Extracellular  Mitochondrion  Cell membrane  \\\n",
       "0        0          0              0              0              1   \n",
       "1        0          0              0              0              1   \n",
       "2        0          0              0              0              1   \n",
       "3        0          0              0              0              1   \n",
       "4        0          0              0              0              1   \n",
       "\n",
       "   Endoplasmic reticulum  Plastid  Golgi apparatus  Lysosome/Vacuole  \\\n",
       "0                      0        0                0                 0   \n",
       "1                      0        0                0                 0   \n",
       "2                      0        0                0                 0   \n",
       "3                      0        0                0                 0   \n",
       "4                      0        0                0                 0   \n",
       "\n",
       "   Peroxisome                                     PaddedSequence  \\\n",
       "0           0  MGLPVSWAPPALWVLGCCALLLSLWALCTACRRPEDAVAPRKRARR...   \n",
       "1           0  MEVLEEPAPGPGGADAAERRGLRRLLLSGFQEELRALLVLAGPAFL...   \n",
       "2           0  MMKTLSSGNCTLNVPAKNSYRMVVLGASRVGKSSIVSRFLNGRFED...   \n",
       "3           0  MAKRTFSNLETFLIFLLVMMSAITVALLSLLFITSGTIENHKDLGG...   \n",
       "4           0  MGNCQAGHNLHLCLAHHPPLVCATLILLLLGLSGLGLGSFLLTHRT...   \n",
       "\n",
       "                                                Mask  \n",
       "0  1111111111111111111111111111111111111111111111...  \n",
       "1  1111111111111111111111111111111111111111111111...  \n",
       "2  1111111111111111111111111111111111111111111111...  \n",
       "3  1111111111111111111111111111111111111111111111...  \n",
       "4  1111111111111111111111111111111111111111111111...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sequence</th>\n",
       "      <th>Membrane</th>\n",
       "      <th>test</th>\n",
       "      <th>Nucleus</th>\n",
       "      <th>Cytoplasm</th>\n",
       "      <th>Extracellular</th>\n",
       "      <th>Mitochondrion</th>\n",
       "      <th>Cell membrane</th>\n",
       "      <th>Endoplasmic reticulum</th>\n",
       "      <th>Plastid</th>\n",
       "      <th>Golgi apparatus</th>\n",
       "      <th>Lysosome/Vacuole</th>\n",
       "      <th>Peroxisome</th>\n",
       "      <th>PaddedSequence</th>\n",
       "      <th>Mask</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>13858</td>\n",
       "      <td>13858.000000</td>\n",
       "      <td>13858</td>\n",
       "      <td>13858.000000</td>\n",
       "      <td>13858.000000</td>\n",
       "      <td>13858.000000</td>\n",
       "      <td>13858.000000</td>\n",
       "      <td>13858.000000</td>\n",
       "      <td>13858.000000</td>\n",
       "      <td>13858.000000</td>\n",
       "      <td>13858.000000</td>\n",
       "      <td>13858.000000</td>\n",
       "      <td>13858.000000</td>\n",
       "      <td>13858</td>\n",
       "      <td>13858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>13804</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13804</td>\n",
       "      <td>957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>MRLPVTVKATKPSFLVIWIRYSSAASSPTVSLNPSGRLQQTLAGSV...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MRLPVTVKATKPSFLVIWIRYSSAASSPTVSLNPSGRLQQTLAGSV...</td>\n",
       "      <td>1111111111111111111111111111111111111111111111...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11085</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>1377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.256386</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.291745</td>\n",
       "      <td>0.183432</td>\n",
       "      <td>0.142373</td>\n",
       "      <td>0.108962</td>\n",
       "      <td>0.096695</td>\n",
       "      <td>0.062202</td>\n",
       "      <td>0.054625</td>\n",
       "      <td>0.025689</td>\n",
       "      <td>0.023164</td>\n",
       "      <td>0.011113</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.436653</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.454582</td>\n",
       "      <td>0.387034</td>\n",
       "      <td>0.349445</td>\n",
       "      <td>0.311603</td>\n",
       "      <td>0.295553</td>\n",
       "      <td>0.241531</td>\n",
       "      <td>0.227256</td>\n",
       "      <td>0.158212</td>\n",
       "      <td>0.150428</td>\n",
       "      <td>0.104833</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Sequence      Membrane  \\\n",
       "count                                               13858  13858.000000   \n",
       "unique                                              13804           NaN   \n",
       "top     MRLPVTVKATKPSFLVIWIRYSSAASSPTVSLNPSGRLQQTLAGSV...           NaN   \n",
       "freq                                                    5           NaN   \n",
       "mean                                                  NaN      0.256386   \n",
       "std                                                   NaN      0.436653   \n",
       "min                                                   NaN      0.000000   \n",
       "25%                                                   NaN      0.000000   \n",
       "50%                                                   NaN      0.000000   \n",
       "75%                                                   NaN      1.000000   \n",
       "max                                                   NaN      1.000000   \n",
       "\n",
       "         test       Nucleus     Cytoplasm  Extracellular  Mitochondrion  \\\n",
       "count   13858  13858.000000  13858.000000   13858.000000   13858.000000   \n",
       "unique      2           NaN           NaN            NaN            NaN   \n",
       "top     False           NaN           NaN            NaN            NaN   \n",
       "freq    11085           NaN           NaN            NaN            NaN   \n",
       "mean      NaN      0.291745      0.183432       0.142373       0.108962   \n",
       "std       NaN      0.454582      0.387034       0.349445       0.311603   \n",
       "min       NaN      0.000000      0.000000       0.000000       0.000000   \n",
       "25%       NaN      0.000000      0.000000       0.000000       0.000000   \n",
       "50%       NaN      0.000000      0.000000       0.000000       0.000000   \n",
       "75%       NaN      1.000000      0.000000       0.000000       0.000000   \n",
       "max       NaN      1.000000      1.000000       1.000000       1.000000   \n",
       "\n",
       "        Cell membrane  Endoplasmic reticulum       Plastid  Golgi apparatus  \\\n",
       "count    13858.000000           13858.000000  13858.000000     13858.000000   \n",
       "unique            NaN                    NaN           NaN              NaN   \n",
       "top               NaN                    NaN           NaN              NaN   \n",
       "freq              NaN                    NaN           NaN              NaN   \n",
       "mean         0.096695               0.062202      0.054625         0.025689   \n",
       "std          0.295553               0.241531      0.227256         0.158212   \n",
       "min          0.000000               0.000000      0.000000         0.000000   \n",
       "25%          0.000000               0.000000      0.000000         0.000000   \n",
       "50%          0.000000               0.000000      0.000000         0.000000   \n",
       "75%          0.000000               0.000000      0.000000         0.000000   \n",
       "max          1.000000               1.000000      1.000000         1.000000   \n",
       "\n",
       "        Lysosome/Vacuole    Peroxisome  \\\n",
       "count       13858.000000  13858.000000   \n",
       "unique               NaN           NaN   \n",
       "top                  NaN           NaN   \n",
       "freq                 NaN           NaN   \n",
       "mean            0.023164      0.011113   \n",
       "std             0.150428      0.104833   \n",
       "min             0.000000      0.000000   \n",
       "25%             0.000000      0.000000   \n",
       "50%             0.000000      0.000000   \n",
       "75%             0.000000      0.000000   \n",
       "max             1.000000      1.000000   \n",
       "\n",
       "                                           PaddedSequence  \\\n",
       "count                                               13858   \n",
       "unique                                              13804   \n",
       "top     MRLPVTVKATKPSFLVIWIRYSSAASSPTVSLNPSGRLQQTLAGSV...   \n",
       "freq                                                    5   \n",
       "mean                                                  NaN   \n",
       "std                                                   NaN   \n",
       "min                                                   NaN   \n",
       "25%                                                   NaN   \n",
       "50%                                                   NaN   \n",
       "75%                                                   NaN   \n",
       "max                                                   NaN   \n",
       "\n",
       "                                                     Mask  \n",
       "count                                               13858  \n",
       "unique                                                957  \n",
       "top     1111111111111111111111111111111111111111111111...  \n",
       "freq                                                 1377  \n",
       "mean                                                  NaN  \n",
       "std                                                   NaN  \n",
       "min                                                   NaN  \n",
       "25%                                                   NaN  \n",
       "50%                                                   NaN  \n",
       "75%                                                   NaN  \n",
       "max                                                   NaN  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include=\"all\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note: We see that various sequences in the dataset are actually repeated, with a sequence even having 5 repetitions in the dataset. We do not do anything about this to stay as close as possible to the original paper. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 11085 training sequences to deeploc1.0-train.csv\n",
      "Saved 2773 test sequences to deeploc1.0-test.csv\n"
     ]
    }
   ],
   "source": [
    "# Split based on the 'test' column\n",
    "train_df = df[df[\"test\"] == False]\n",
    "test_df = df[df[\"test\"] == True]\n",
    "\n",
    "# Save to CSV files\n",
    "train_df.to_csv(train_path, index=False)\n",
    "test_df.to_csv(test_path, index=False)\n",
    "\n",
    "print(f\"Saved {len(train_df)} training sequences to deeploc1.0-train.csv\")\n",
    "print(f\"Saved {len(test_df)} test sequences to deeploc1.0-test.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DeepLoc 2.0/2.1 EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see how the model performs with more (current) data, we also used the dataset that DeepLoc 2.0/2.1 offers. This data was sourced from the [HTU website](https://services.healthtech.dtu.dk/services/DeepLoc-2.0/) We only used the training/validation set and used the validation set as our training set as we will not perform extensive hyperparameter tuning.\n",
    "\n",
    "> Note: We follow a similar processing approach as in DeepLoc 1.0 to stay as true as possible to the original paper with this new dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = './data/DeepLoc2.0/deeploc_data_2.1.csv'\n",
    "train_path = './data/DeepLoc2.0/deeploc2.1_training_processed.csv'\n",
    "test_path = './data/DeepLoc2.0/deeploc2.1_test_processed.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Location counts:\n",
      "Cytoplasm: 9870\n",
      "Nucleus: 9720\n",
      "Extracellular: 3301\n",
      "Cell membrane: 4187\n",
      "Mitochondrion: 2590\n",
      "Plastid: 1047\n",
      "Endoplasmic reticulum: 2180\n",
      "Lysosome/Vacuole: 1496\n",
      "Golgi apparatus: 1279\n",
      "Peroxisome: 304\n",
      "Total Number of sequences in dataset: 35974\n"
     ]
    }
   ],
   "source": [
    "# Count the number of sequences for each location in the CSV file\n",
    "df = pd.read_csv(csv_path, delimiter=',')\n",
    "\n",
    "# Columns corresponding to subcellular locations/columns in the CSV file\n",
    "location_columns = [\n",
    "        \"Cytoplasm\",\n",
    "        \"Nucleus\",\n",
    "        \"Extracellular\",\n",
    "        \"Cell membrane\",\n",
    "        \"Mitochondrion\",\n",
    "        \"Plastid\",\n",
    "        \"Endoplasmic reticulum\",\n",
    "        \"Lysosome/Vacuole\",\n",
    "        \"Golgi apparatus\",\n",
    "        \"Peroxisome\"\n",
    "        ]\n",
    "\n",
    "def count_locations(df):\n",
    "    \"\"\" Count the number of sequences for each location in the CSV file. \"\"\"\n",
    "    # Count occurrences\n",
    "    location_counts = df[location_columns].sum().astype(int)\n",
    "\n",
    "    print(\"Location counts:\")\n",
    "    for location, count in location_counts.items():\n",
    "        print(f\"{location}: {count}\")\n",
    "    total = location_counts.sum()\n",
    "    print(f\"Total Number of sequences in dataset: {total}\")\n",
    "\n",
    "\n",
    "count_locations(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note: We end up with 35974 sequences, this is the same number of sequences as the authors in Deeploc 2.0 as mentioned in their Supplementary Table S2. Unlike DeepLoc 1.0, DeepLoc 2.0 performs multi-label localization prediction. Therefore, we filter out any sequences with more than one localization for our specific use-case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Location counts (single-label only):\n",
      "Cytoplasm: 4582\n",
      "Nucleus: 5462\n",
      "Extracellular: 2944\n",
      "Cell membrane: 2770\n",
      "Mitochondrion: 2062\n",
      "Plastid: 932\n",
      "Endoplasmic reticulum: 1331\n",
      "Lysosome/Vacuole: 761\n",
      "Golgi apparatus: 556\n",
      "Peroxisome: 219\n",
      "Total: 21619\n"
     ]
    }
   ],
   "source": [
    "# Filter out sequences with multiple locations\n",
    "def count_locations_single_label(df):\n",
    "\n",
    "    # Filter: keep only rows with exactly 1 location\n",
    "    df_single_label = df[df[location_columns].sum(axis=1) == 1]\n",
    "\n",
    "    # Count occurrences in single-label data\n",
    "    location_counts = df_single_label[location_columns].sum().astype(int)\n",
    "\n",
    "    print(\"Location counts (single-label only):\")\n",
    "    for location, count in location_counts.items():\n",
    "        print(f\"{location}: {count}\")\n",
    "    print(f\"Total: {location_counts.sum()}\")\n",
    "\n",
    "    return df_single_label\n",
    "\n",
    "# Returns a filtered DataFrame with sequences that have only one location\n",
    "df_filtered = count_locations_single_label(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Membrane type counts:\n",
      "0.0: 15261\n",
      "1.0: 6358\n"
     ]
    }
   ],
   "source": [
    "counts = df_filtered['Membrane'].value_counts()\n",
    "# Print the counts for each Membrane type\n",
    "print(\"Membrane type counts:\")\n",
    "for location, count in counts.items():\n",
    "    print(f\"{location}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note: This dataset is used for k-fold cross-validation. Meaning that over K iterations, K-1 are used for training and 1 is used for validation. Again, as we do not perform any extensive hyperparameter tuning, we will simply use their validation set as our test set. This is a valid approach as the authors have already perform the homology-based partioning across different folds, ensuring <30% homology."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3186, 16)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensure a maximum protein length of 1000\n",
    "df[df['Sequence'].str.len() > 1000].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that 3186 samples have to be truncated. We do this as they suggest in DeepLoc 1.0, by taking out amino-acids from the center of the sequence.\n",
    "\n",
    "Finally, amino acids shorter than length 1000 must be padded to length 1000. Additionally, a mask must be generated to ensure the attention mechanism ignores padding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 1000\n",
    "PAD_CHAR = '-'\n",
    "\n",
    "# Remove the center of the sequence, keeping the first and last 500.\n",
    "def truncate_sequence(seq, max_len=1000):\n",
    "    if len(seq) <= max_len:\n",
    "        return seq\n",
    "    half = max_len // 2\n",
    "    return seq[:half] + seq[-half:]\n",
    "\n",
    "# Pad the sequence in the center with a specified character\n",
    "def pad_middle(seq, max_len=MAX_LEN, pad_char=PAD_CHAR):\n",
    "    pad_total = max_len - len(seq)\n",
    "    half_idx = len(seq) // 2\n",
    "    return seq[:half_idx] + (pad_char * pad_total) + seq[half_idx:] \n",
    "\n",
    "# Prepare the sequence for the the processed training dataset\n",
    "def prepare_sequence(seq, max_len=MAX_LEN, pad_char=PAD_CHAR):\n",
    "    if len(seq) > max_len:\n",
    "        return truncate_sequence(seq, max_len)\n",
    "    elif len(seq) < max_len:\n",
    "        return pad_middle(seq, max_len, pad_char)\n",
    "    else:\n",
    "        return seq  # already length 1000\n",
    "\n",
    "# Generate a mask for the sequence\n",
    "def generate_mask(seq, pad_char=PAD_CHAR):\n",
    "    \"\"\" The mask is a string of 0s and 1s, where 1 indicates the presence of an amino acid and 0 indicates a padding character \"\"\"\n",
    "    return ''.join(['0' if aa == pad_char else '1' for aa in seq])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\neere\\AppData\\Local\\Temp\\ipykernel_17132\\1970824193.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['PaddedSequence'] = df_filtered['Sequence'].apply(prepare_sequence)\n",
      "C:\\Users\\neere\\AppData\\Local\\Temp\\ipykernel_17132\\1970824193.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['Mask'] = df_filtered['PaddedSequence'].apply(generate_mask)\n"
     ]
    }
   ],
   "source": [
    "# Create a new column with truncated sequences\n",
    "df_filtered['PaddedSequence'] = df_filtered['Sequence'].apply(prepare_sequence)\n",
    "df_filtered['Mask'] = df_filtered['PaddedSequence'].apply(generate_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to a new CSV\n",
    "df_filtered.to_csv(train_path, index=False)\n",
    "# Filter by partition\n",
    "df_train = df_filtered[df_filtered['Partition'] != 4]  # Partitions 0–3 for training/validation\n",
    "df_test = df_filtered[df_filtered['Partition'] == 4]       # Partition 4 for testing\n",
    "\n",
    "# Save to separate CSV files\n",
    "df_train.to_csv(train_path, index=False)\n",
    "df_test.to_csv(test_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 18)\n",
      "(17351, 18)\n",
      "(17351, 18)\n",
      "(17351, 18)\n"
     ]
    }
   ],
   "source": [
    "# Examine the newly generated CSV files\n",
    "df_processed = pd.read_csv(train_path, delimiter=',')\n",
    "print(df_processed[df_processed['Sequence'].str.len() == 1000].shape)\n",
    "print(df_processed[df_processed['PaddedSequence'].str.len() == 1000].shape)\n",
    "print(df_processed[df_processed['Mask'].str.len() == 1000].shape)\n",
    "print(df_processed.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Converting the sequence to a feature vector using BLOSUM-62"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLOSUM(62, default=0, {'A': defaultdict(<function BLOSUM.__init__.<locals>.<lambda> at 0x000001B72E13EA70>, {'A': 4.0, 'R': -1.0, 'N': -2.0, 'D': -2.0, 'C': 0.0, 'Q': -1.0, 'E': -1.0, 'G': 0.0, 'H': -2.0, 'I': -1.0, 'L': -1.0, 'K': -1.0, 'M': -1.0, 'F': -2.0, 'P': -1.0, 'S': 1.0, 'T': 0.0, 'W': -3.0, 'Y': -2.0, 'V': 0.0, 'B': -2.0, 'J': -1.0, 'Z': -1.0, 'X': -1.0, '*': -4.0}), 'R': defaultdict(<function BLOSUM.__init__.<locals>.<lambda> at 0x000001B72E13D510>, {'A': -1.0, 'R': 5.0, 'N': 0.0, 'D': -2.0, 'C': -3.0, 'Q': 1.0, 'E': 0.0, 'G': -2.0, 'H': 0.0, 'I': -3.0, 'L': -2.0, 'K': 2.0, 'M': -1.0, 'F': -3.0, 'P': -2.0, 'S': -1.0, 'T': -1.0, 'W': -3.0, 'Y': -2.0, 'V': -3.0, 'B': -1.0, 'J': -2.0, 'Z': 0.0, 'X': -1.0, '*': -4.0}), 'N': defaultdict(<function BLOSUM.__init__.<locals>.<lambda> at 0x000001B730CB9480>, {'A': -2.0, 'R': 0.0, 'N': 6.0, 'D': 1.0, 'C': -3.0, 'Q': 0.0, 'E': 0.0, 'G': 0.0, 'H': 1.0, 'I': -3.0, 'L': -3.0, 'K': 0.0, 'M': -2.0, 'F': -3.0, 'P': -2.0, 'S': 1.0, 'T': 0.0, 'W': -4.0, 'Y': -2.0, 'V': -3.0, 'B': 4.0, 'J': -3.0, 'Z': 0.0, 'X': -1.0, '*': -4.0}), 'D': defaultdict(<function BLOSUM.__init__.<locals>.<lambda> at 0x000001B730CB9360>, {'A': -2.0, 'R': -2.0, 'N': 1.0, 'D': 6.0, 'C': -3.0, 'Q': 0.0, 'E': 2.0, 'G': -1.0, 'H': -1.0, 'I': -3.0, 'L': -4.0, 'K': -1.0, 'M': -3.0, 'F': -3.0, 'P': -1.0, 'S': 0.0, 'T': -1.0, 'W': -4.0, 'Y': -3.0, 'V': -3.0, 'B': 4.0, 'J': -3.0, 'Z': 1.0, 'X': -1.0, '*': -4.0}), 'C': defaultdict(<function BLOSUM.__init__.<locals>.<lambda> at 0x000001B730CB9510>, {'A': 0.0, 'R': -3.0, 'N': -3.0, 'D': -3.0, 'C': 9.0, 'Q': -3.0, 'E': -4.0, 'G': -3.0, 'H': -3.0, 'I': -1.0, 'L': -1.0, 'K': -3.0, 'M': -1.0, 'F': -2.0, 'P': -3.0, 'S': -1.0, 'T': -1.0, 'W': -2.0, 'Y': -2.0, 'V': -1.0, 'B': -3.0, 'J': -1.0, 'Z': -3.0, 'X': -1.0, '*': -4.0}), 'Q': defaultdict(<function BLOSUM.__init__.<locals>.<lambda> at 0x000001B730CB95A0>, {'A': -1.0, 'R': 1.0, 'N': 0.0, 'D': 0.0, 'C': -3.0, 'Q': 5.0, 'E': 2.0, 'G': -2.0, 'H': 0.0, 'I': -3.0, 'L': -2.0, 'K': 1.0, 'M': 0.0, 'F': -3.0, 'P': -1.0, 'S': 0.0, 'T': -1.0, 'W': -2.0, 'Y': -1.0, 'V': -2.0, 'B': 0.0, 'J': -2.0, 'Z': 4.0, 'X': -1.0, '*': -4.0}), 'E': defaultdict(<function BLOSUM.__init__.<locals>.<lambda> at 0x000001B730CB9630>, {'A': -1.0, 'R': 0.0, 'N': 0.0, 'D': 2.0, 'C': -4.0, 'Q': 2.0, 'E': 5.0, 'G': -2.0, 'H': 0.0, 'I': -3.0, 'L': -3.0, 'K': 1.0, 'M': -2.0, 'F': -3.0, 'P': -1.0, 'S': 0.0, 'T': -1.0, 'W': -3.0, 'Y': -2.0, 'V': -2.0, 'B': 1.0, 'J': -3.0, 'Z': 4.0, 'X': -1.0, '*': -4.0}), 'G': defaultdict(<function BLOSUM.__init__.<locals>.<lambda> at 0x000001B730CB96C0>, {'A': 0.0, 'R': -2.0, 'N': 0.0, 'D': -1.0, 'C': -3.0, 'Q': -2.0, 'E': -2.0, 'G': 6.0, 'H': -2.0, 'I': -4.0, 'L': -4.0, 'K': -2.0, 'M': -3.0, 'F': -3.0, 'P': -2.0, 'S': 0.0, 'T': -2.0, 'W': -2.0, 'Y': -3.0, 'V': -3.0, 'B': -1.0, 'J': -4.0, 'Z': -2.0, 'X': -1.0, '*': -4.0}), 'H': defaultdict(<function BLOSUM.__init__.<locals>.<lambda> at 0x000001B730CB9750>, {'A': -2.0, 'R': 0.0, 'N': 1.0, 'D': -1.0, 'C': -3.0, 'Q': 0.0, 'E': 0.0, 'G': -2.0, 'H': 8.0, 'I': -3.0, 'L': -3.0, 'K': -1.0, 'M': -2.0, 'F': -1.0, 'P': -2.0, 'S': -1.0, 'T': -2.0, 'W': -2.0, 'Y': 2.0, 'V': -3.0, 'B': 0.0, 'J': -3.0, 'Z': 0.0, 'X': -1.0, '*': -4.0}), 'I': defaultdict(<function BLOSUM.__init__.<locals>.<lambda> at 0x000001B730CB97E0>, {'A': -1.0, 'R': -3.0, 'N': -3.0, 'D': -3.0, 'C': -1.0, 'Q': -3.0, 'E': -3.0, 'G': -4.0, 'H': -3.0, 'I': 4.0, 'L': 2.0, 'K': -3.0, 'M': 1.0, 'F': 0.0, 'P': -3.0, 'S': -2.0, 'T': -1.0, 'W': -3.0, 'Y': -1.0, 'V': 3.0, 'B': -3.0, 'J': 3.0, 'Z': -3.0, 'X': -1.0, '*': -4.0}), 'L': defaultdict(<function BLOSUM.__init__.<locals>.<lambda> at 0x000001B730CB9870>, {'A': -1.0, 'R': -2.0, 'N': -3.0, 'D': -4.0, 'C': -1.0, 'Q': -2.0, 'E': -3.0, 'G': -4.0, 'H': -3.0, 'I': 2.0, 'L': 4.0, 'K': -2.0, 'M': 2.0, 'F': 0.0, 'P': -3.0, 'S': -2.0, 'T': -1.0, 'W': -2.0, 'Y': -1.0, 'V': 1.0, 'B': -4.0, 'J': 3.0, 'Z': -3.0, 'X': -1.0, '*': -4.0}), 'K': defaultdict(<function BLOSUM.__init__.<locals>.<lambda> at 0x000001B730CB9900>, {'A': -1.0, 'R': 2.0, 'N': 0.0, 'D': -1.0, 'C': -3.0, 'Q': 1.0, 'E': 1.0, 'G': -2.0, 'H': -1.0, 'I': -3.0, 'L': -2.0, 'K': 5.0, 'M': -1.0, 'F': -3.0, 'P': -1.0, 'S': 0.0, 'T': -1.0, 'W': -3.0, 'Y': -2.0, 'V': -2.0, 'B': 0.0, 'J': -3.0, 'Z': 1.0, 'X': -1.0, '*': -4.0}), 'M': defaultdict(<function BLOSUM.__init__.<locals>.<lambda> at 0x000001B730CB9990>, {'A': -1.0, 'R': -1.0, 'N': -2.0, 'D': -3.0, 'C': -1.0, 'Q': 0.0, 'E': -2.0, 'G': -3.0, 'H': -2.0, 'I': 1.0, 'L': 2.0, 'K': -1.0, 'M': 5.0, 'F': 0.0, 'P': -2.0, 'S': -1.0, 'T': -1.0, 'W': -1.0, 'Y': -1.0, 'V': 1.0, 'B': -3.0, 'J': 2.0, 'Z': -1.0, 'X': -1.0, '*': -4.0}), 'F': defaultdict(<function BLOSUM.__init__.<locals>.<lambda> at 0x000001B730CB9A20>, {'A': -2.0, 'R': -3.0, 'N': -3.0, 'D': -3.0, 'C': -2.0, 'Q': -3.0, 'E': -3.0, 'G': -3.0, 'H': -1.0, 'I': 0.0, 'L': 0.0, 'K': -3.0, 'M': 0.0, 'F': 6.0, 'P': -4.0, 'S': -2.0, 'T': -2.0, 'W': 1.0, 'Y': 3.0, 'V': -1.0, 'B': -3.0, 'J': 0.0, 'Z': -3.0, 'X': -1.0, '*': -4.0}), 'P': defaultdict(<function BLOSUM.__init__.<locals>.<lambda> at 0x000001B730CB9AB0>, {'A': -1.0, 'R': -2.0, 'N': -2.0, 'D': -1.0, 'C': -3.0, 'Q': -1.0, 'E': -1.0, 'G': -2.0, 'H': -2.0, 'I': -3.0, 'L': -3.0, 'K': -1.0, 'M': -2.0, 'F': -4.0, 'P': 7.0, 'S': -1.0, 'T': -1.0, 'W': -4.0, 'Y': -3.0, 'V': -2.0, 'B': -2.0, 'J': -3.0, 'Z': -1.0, 'X': -1.0, '*': -4.0}), 'S': defaultdict(<function BLOSUM.__init__.<locals>.<lambda> at 0x000001B730CB9B40>, {'A': 1.0, 'R': -1.0, 'N': 1.0, 'D': 0.0, 'C': -1.0, 'Q': 0.0, 'E': 0.0, 'G': 0.0, 'H': -1.0, 'I': -2.0, 'L': -2.0, 'K': 0.0, 'M': -1.0, 'F': -2.0, 'P': -1.0, 'S': 4.0, 'T': 1.0, 'W': -3.0, 'Y': -2.0, 'V': -2.0, 'B': 0.0, 'J': -2.0, 'Z': 0.0, 'X': -1.0, '*': -4.0}), 'T': defaultdict(<function BLOSUM.__init__.<locals>.<lambda> at 0x000001B730CB9BD0>, {'A': 0.0, 'R': -1.0, 'N': 0.0, 'D': -1.0, 'C': -1.0, 'Q': -1.0, 'E': -1.0, 'G': -2.0, 'H': -2.0, 'I': -1.0, 'L': -1.0, 'K': -1.0, 'M': -1.0, 'F': -2.0, 'P': -1.0, 'S': 1.0, 'T': 5.0, 'W': -2.0, 'Y': -2.0, 'V': 0.0, 'B': -1.0, 'J': -1.0, 'Z': -1.0, 'X': -1.0, '*': -4.0}), 'W': defaultdict(<function BLOSUM.__init__.<locals>.<lambda> at 0x000001B730CB9C60>, {'A': -3.0, 'R': -3.0, 'N': -4.0, 'D': -4.0, 'C': -2.0, 'Q': -2.0, 'E': -3.0, 'G': -2.0, 'H': -2.0, 'I': -3.0, 'L': -2.0, 'K': -3.0, 'M': -1.0, 'F': 1.0, 'P': -4.0, 'S': -3.0, 'T': -2.0, 'W': 11.0, 'Y': 2.0, 'V': -3.0, 'B': -4.0, 'J': -2.0, 'Z': -2.0, 'X': -1.0, '*': -4.0}), 'Y': defaultdict(<function BLOSUM.__init__.<locals>.<lambda> at 0x000001B730CB9CF0>, {'A': -2.0, 'R': -2.0, 'N': -2.0, 'D': -3.0, 'C': -2.0, 'Q': -1.0, 'E': -2.0, 'G': -3.0, 'H': 2.0, 'I': -1.0, 'L': -1.0, 'K': -2.0, 'M': -1.0, 'F': 3.0, 'P': -3.0, 'S': -2.0, 'T': -2.0, 'W': 2.0, 'Y': 7.0, 'V': -1.0, 'B': -3.0, 'J': -1.0, 'Z': -2.0, 'X': -1.0, '*': -4.0}), 'V': defaultdict(<function BLOSUM.__init__.<locals>.<lambda> at 0x000001B730CB9D80>, {'A': 0.0, 'R': -3.0, 'N': -3.0, 'D': -3.0, 'C': -1.0, 'Q': -2.0, 'E': -2.0, 'G': -3.0, 'H': -3.0, 'I': 3.0, 'L': 1.0, 'K': -2.0, 'M': 1.0, 'F': -1.0, 'P': -2.0, 'S': -2.0, 'T': 0.0, 'W': -3.0, 'Y': -1.0, 'V': 4.0, 'B': -3.0, 'J': 2.0, 'Z': -2.0, 'X': -1.0, '*': -4.0}), 'B': defaultdict(<function BLOSUM.__init__.<locals>.<lambda> at 0x000001B730CB9E10>, {'A': -2.0, 'R': -1.0, 'N': 4.0, 'D': 4.0, 'C': -3.0, 'Q': 0.0, 'E': 1.0, 'G': -1.0, 'H': 0.0, 'I': -3.0, 'L': -4.0, 'K': 0.0, 'M': -3.0, 'F': -3.0, 'P': -2.0, 'S': 0.0, 'T': -1.0, 'W': -4.0, 'Y': -3.0, 'V': -3.0, 'B': 4.0, 'J': -3.0, 'Z': 0.0, 'X': -1.0, '*': -4.0}), 'J': defaultdict(<function BLOSUM.__init__.<locals>.<lambda> at 0x000001B730CB9EA0>, {'A': -1.0, 'R': -2.0, 'N': -3.0, 'D': -3.0, 'C': -1.0, 'Q': -2.0, 'E': -3.0, 'G': -4.0, 'H': -3.0, 'I': 3.0, 'L': 3.0, 'K': -3.0, 'M': 2.0, 'F': 0.0, 'P': -3.0, 'S': -2.0, 'T': -1.0, 'W': -2.0, 'Y': -1.0, 'V': 2.0, 'B': -3.0, 'J': 3.0, 'Z': -3.0, 'X': -1.0, '*': -4.0}), 'Z': defaultdict(<function BLOSUM.__init__.<locals>.<lambda> at 0x000001B730CB9F30>, {'A': -1.0, 'R': 0.0, 'N': 0.0, 'D': 1.0, 'C': -3.0, 'Q': 4.0, 'E': 4.0, 'G': -2.0, 'H': 0.0, 'I': -3.0, 'L': -3.0, 'K': 1.0, 'M': -1.0, 'F': -3.0, 'P': -1.0, 'S': 0.0, 'T': -1.0, 'W': -2.0, 'Y': -2.0, 'V': -2.0, 'B': 0.0, 'J': -3.0, 'Z': 4.0, 'X': -1.0, '*': -4.0}), 'X': defaultdict(<function BLOSUM.__init__.<locals>.<lambda> at 0x000001B730CB9FC0>, {'A': -1.0, 'R': -1.0, 'N': -1.0, 'D': -1.0, 'C': -1.0, 'Q': -1.0, 'E': -1.0, 'G': -1.0, 'H': -1.0, 'I': -1.0, 'L': -1.0, 'K': -1.0, 'M': -1.0, 'F': -1.0, 'P': -1.0, 'S': -1.0, 'T': -1.0, 'W': -1.0, 'Y': -1.0, 'V': -1.0, 'B': -1.0, 'J': -1.0, 'Z': -1.0, 'X': -1.0, '*': -4.0}), '*': defaultdict(<function BLOSUM.__init__.<locals>.<lambda> at 0x000001B730CBA050>, {'A': -4.0, 'R': -4.0, 'N': -4.0, 'D': -4.0, 'C': -4.0, 'Q': -4.0, 'E': -4.0, 'G': -4.0, 'H': -4.0, 'I': -4.0, 'L': -4.0, 'K': -4.0, 'M': -4.0, 'F': -4.0, 'P': -4.0, 'S': -4.0, 'T': -4.0, 'W': -4.0, 'Y': -4.0, 'V': -4.0, 'B': -4.0, 'J': -4.0, 'Z': -4.0, 'X': -4.0, '*': 1.0})}\n",
      "['A', 'R', 'N', 'D', 'C', 'Q', 'E', 'G', 'H', 'I', 'L', 'K', 'M', 'F', 'P', 'S', 'T', 'W', 'Y', 'V', 'B', 'J', 'Z', 'X', '*']\n",
      "25\n"
     ]
    }
   ],
   "source": [
    "matrix = bl.BLOSUM(62, default=0)\n",
    "print(matrix)\n",
    "\n",
    "# Get all the keys in the dictionary and convert them to a list\n",
    "matrix_keys = list(matrix.keys())\n",
    "\n",
    "print(matrix_keys)\n",
    "print(len(matrix_keys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "['A', 'R', 'N', 'D', 'C', 'Q', 'E', 'G', 'H', 'I', 'L', 'K', 'M', 'F', 'P', 'S', 'T', 'W', 'Y', 'V']\n"
     ]
    }
   ],
   "source": [
    "# Remove B, Z, X, J, * from the keys list as they are not standard amino acids and DeepLoc 1.0 only has 20 features.\n",
    "matrix_keys = [key for key in matrix_keys if key not in ['B', 'Z', 'X', 'J', '*']]\n",
    "print(len(matrix_keys))\n",
    "print(matrix_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_sequence_with_blosum(seq):\n",
    "    \"\"\"\n",
    "    Encode a sequence using BLOSUM62, applying the mask.\n",
    "    Returns: (max_len x 20) numpy array\n",
    "    \"\"\"\n",
    "    encoded = np.zeros((MAX_LEN, len(matrix_keys)), dtype=np.float32)\n",
    "    for i, aa in enumerate(seq):\n",
    "        encoded[i] = [matrix[aa][other_aa] for other_aa in matrix_keys]\n",
    "        # We ensured the default was 0, so no need to use the mask.\n",
    "    return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4. -1. -2. ... -3. -2.  0.]\n",
      " [ 0. -3. -3. ... -2. -2. -1.]\n",
      " [-2. -2.  1. ... -4. -3. -3.]\n",
      " ...\n",
      " [ 0.  0.  0. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ...  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "# Test the encoding function\n",
    "features = encode_sequence_with_blosum(\"ACDXYZ--\")\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Creating a dataset which encodes sequences & returns batches for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom dataset class for DeepLoc\n",
    "class DeepLocDataset(Dataset):\n",
    "    def __init__(self, df, label_columns, matrix):\n",
    "        self.sequences = df['PaddedSequence'].values # Fetch the processed sequences\n",
    "        self.masks = df['Mask'].values # Fetch the masks\n",
    "        self.labels = df[label_columns].values.astype(np.float32) # Convert labels to float32\n",
    "        self.matrix = matrix # BLOSUM matrix\n",
    "        self.max_len = MAX_LEN\n",
    "        self.matrix_keys = list(matrix.keys())\n",
    "        self.matrix_keys = [key for key in self.matrix_keys if key not in ['B', 'Z', 'X', 'J', '*']]\n",
    "        self.num_features = len(self.matrix_keys)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq = self.sequences[idx]\n",
    "        mask = self.masks[idx]\n",
    "        label = self.labels[idx]\n",
    "        encoded_seq = encode_sequence_with_blosum(seq)\n",
    "        mask_tensor = torch.tensor([int(m) for m in mask], dtype=torch.float32)\n",
    "        return torch.tensor(encoded_seq), torch.tensor(label), mask_tensor # Return the encoded sequence, label, and mask tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dataset and DataLoader\n",
    "dataset = DeepLocDataset(df_filtered, location_columns, matrix)\n",
    "loader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_batch shape: torch.Size([32, 1000, 20])\n",
      "y_batch shape: torch.Size([32, 10])\n",
      "mask_batch shape: torch.Size([32, 1000])\n"
     ]
    }
   ],
   "source": [
    "# Test the DataLoader\n",
    "for x_batch, y_batch, mask_batch in loader:\n",
    "    print(\"x_batch shape:\", x_batch.shape) # x_batch: (B, 1000, 20)\n",
    "    print(\"y_batch shape:\", y_batch.shape) # y_batch: (B, 10)\n",
    "    print(\"mask_batch shape:\", mask_batch.shape) # mask_batch: (B, 1000)\n",
    "    break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepLoc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
